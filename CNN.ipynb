!pip3 install torch 
!pip3 install torchvision
!pip3 install tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
from torchvision import transforms, utils, datasets
from tqdm import tqdm
 
assert torch.cuda.is_available() # You need to request a GPU from Runtime > Change Runtime Type

from torch.nn.parameter import Parameter
import pdb

import torchvision
import os
import gzip
import tarfile
import gc
from IPython.core.ultratb import AutoFormattedTB
__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)

class ConvNet(nn.Module):
    def __init__(self, dataset):
      super(ConvNet,self).__init__()
        
      self.relu = nn.ReLU()
#       self.norm = nn.Batchnorm2d()#after convdown you want to use the norm with the second param aka 62 128 you do 128
      
      
      self.layer1 = nn.Conv2d(3,64,3,padding=1)
      self.layer2 = nn.Conv2d(64,64,3,padding=1)
      self.convDown1 = nn.Conv2d(64,64,2,stride=2,padding=0)
      self.norm64 = nn.BatchNorm2d(64)


      self.layer3 = nn.Conv2d(64,128,3,padding=1)
      self.layer4 = nn.Conv2d(128,128,3,padding=1)
      self.convDown2 = nn.Conv2d(128,128,2,stride=2,padding=0)
      self.norm128 = nn.BatchNorm2d(128)

      self.layer5 = nn.Conv2d(128,256,3,padding=1)
      self.layer6 = nn.Conv2d(256,256,3,padding=1)
      self.convDown3 = nn.Conv2d(256,256,2,stride=2,padding=0)
      self.norm256 = nn.BatchNorm2d(256)

      self.layer7 = nn.Conv2d(256,512,3,padding=1)
      self.layer8 = nn.Conv2d(512,512,3,padding=1)
      self.convDown4 = nn.Conv2d(512,512,2,stride=2,padding=0)
      self.norm512 = nn.BatchNorm2d(512)

      self.layer9 = nn.Conv2d(512,1024,3,padding=1)
      self.layer10 = nn.Conv2d(1024,1024,3,padding=1)
      self.transpose1 = nn.ConvTranspose2d(1024,512,2,stride=2,padding=0)
      #self.norm1024 = nn.BatchNorm2d(1024)

      self.layer11 = nn.Conv2d(1024,512,3,padding=1)
      self.layer12 = nn.Conv2d(512,512,3,padding=1)
      self.transpose2 = nn.ConvTranspose2d(512,256,2,stride=2,padding=0)

      self.layer13 = nn.Conv2d(512,256,3,padding=1)
      self.layer14 = nn.Conv2d(256,256,3,padding=1)
      self.transpose3 = nn.ConvTranspose2d(256,128,2,stride=2,padding=0)

      self.layer15 = nn.Conv2d(256,128,3,padding=1)
      self.layer16 = nn.Conv2d(128,128,3,padding=1)
      self.transpose4 = nn.ConvTranspose2d(128,64,2,stride=2,padding=0)

      self.layer17 = nn.Conv2d(128,64,3,padding=1)
      self.layer18 = nn.Conv2d(64,64,3,padding=1)
        
      #self.finalDown = nn.Conv2d(64,2,1,padding=0) #this is the one by one
        
        
        
        
      self.mysigmoid = nn.Sequential(nn.Conv2d(64,2,1,1,0),nn.Sigmoid())
        
        #maybe add sigmoud?
        
    def forward(self,x):
      output = self.layer1(x)
      output = self.norm64(output)
      output = self.relu(output)
      output = self.layer2(output)
      output = self.norm64(output)
      outputRel1 = self.relu(output)
      output= self.convDown1(outputRel1)
      output = self.norm64(output)
      
      
      
      output = self.layer3(output)
      output = self.norm128(output)
      output = self.relu(output)
      output = self.layer4(output)
      output = self.norm128(output)
      outputRel2 = self.relu(output)
      output = self.convDown2(outputRel2)
      output = self.norm128(output)
      
      output = self.layer5(output)
      output = self.norm256(output)
      output = self.relu(output)
      output = self.layer6(output)
      output = self.norm256(output)
      outputRel3 = self.relu(output)
      output = self.convDown3(outputRel3)
      output = self.norm256(output)
      
      output = self.layer7(output)
      output = self.norm512(output)
      output = self.relu(output)
      output = self.layer8(output)
      output = self.norm512(output)
      outputRel4 = self.relu(output)
      output = self.convDown4(outputRel4)
      output = self.norm512(output)
      
      output = self.layer9(output)
      output = self.relu(output)
      output = self.layer10(output)
      outputRel5 = self.relu(output)
      
      outputTrans1 = self.transpose1(outputRel5)
      outputcat1 = torch.cat((outputTrans1,outputRel4),1)
      
      
      output = self.layer11(outputcat1)
      output = self.relu(output)
      output = self.layer12(output)
      output = self.relu(output)
      
      outputTrans2 = self.transpose2(output)
      outputcat2 = torch.cat((outputRel3,outputTrans2),1)
      
      output = self.layer13(outputcat2)
      output = self.relu(output)
      output = self.layer14(output)
      output = self.relu(output)
      
      outputTrans3 = self.transpose3(output)
      outputcat3 = torch.cat((outputRel2,outputTrans3),1)
      
      output = self.layer15(outputcat3)
      output = self.relu(output)
      output = self.layer16(output)
      output = self.relu(output)
      
      outputTrans4 = self.transpose4(output)
      outputcat4 = torch.cat((outputRel1,outputTrans4),1)
      
      output = self.layer17(outputcat4)
      output = self.relu(output)
      output = self.layer18(output)
      output = self.relu(output)
      
      #output = self.finalDown(output)
      
      output = self.mysigmoid(output)
      
      return output;
      
      
     
      
      
      
      
      
      
     
      
      #tpd.set
        
        

class CancerDataset(Dataset):
  def __init__(self, root, download=True, size=512, train=True):#will need to change back to size 512
    if download and not os.path.exists(os.path.join(root, 'cancer_data')):
      datasets.utils.download_url('http://liftothers.org/cancer_data.tar.gz', root, 'cancer_data.tar.gz', None)
      self.extract_gzip(os.path.join(root, 'cancer_data.tar.gz'))
      self.extract_tar(os.path.join(root, 'cancer_data.tar'))
 
    postfix = 'train' if train else 'test'
    root = os.path.join(root, 'cancer_data', 'cancer_data')
    self.dataset_folder = torchvision.datasets.ImageFolder(os.path.join(root, 'inputs_' + postfix) ,transform = transforms.Compose([transforms.Resize(size),transforms.ToTensor()]))
    self.label_folder = torchvision.datasets.ImageFolder(os.path.join(root, 'outputs_' + postfix) ,transform = transforms.Compose([transforms.Resize(size),transforms.ToTensor()]))
 
  @staticmethod
  def extract_gzip(gzip_path, remove_finished=False):
    print('Extracting {}'.format(gzip_path))
    with open(gzip_path.replace('.gz', ''), 'wb') as out_f, gzip.GzipFile(gzip_path) as zip_f:
      out_f.write(zip_f.read())
    if remove_finished:
      os.unlink(gzip_path)
 
  @staticmethod
  def extract_tar(tar_path):
    print('Untarring {}'.format(tar_path))
    z = tarfile.TarFile(tar_path)
    z.extractall(tar_path.replace('.tar', ''))
 
 
  def __getitem__(self,index):
    img = self.dataset_folder[index]
    label = self.label_folder[index]
    return img[0],label[0][0]
 
  def __len__(self):
    return len(self.dataset_folder)
    
    
validation = []
loss_array = []
accuracy_array = []

train_dataset = CancerDataset('/tmp/cancer_data',train = True)
testset = CancerDataset('/tmp/cancer_data', train = False)

validation = []
loss_array = []
accuracy_array = []


def scope():
  try:
    model = ConvNet(train_dataset)
    model = model.cuda()
    objective = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(),lr=1e-4)
    train_loader = DataLoader( train_dataset
                              ,
                                batch_size = 4,
                                shuffle=True,
                                pin_memory = True)#set batch size to 4 and shuffle to true

    gc.collect()
    print(torch.cuda.memory_allocated(0) / 1e9)
 
    for epoch in range(4):
      my_loss = []
      m_loss = 0
      m_acc = 0
      my_accuracy = []
  
      loop = tqdm(total=len(train_loader), position=0, leave=False)

      for batch, (x, y_truth) in enumerate(train_loader):
       
        x,y_truth = x.cuda(async = True),y_truth.cuda(async = True)

        optimizer.zero_grad()
        y_hat = model(x)
        
        
        loss = objective(y_hat , y_truth.long())
        
        loss.backward()
        my_loss.append(loss.item())
        m_loss = m_loss + loss.item()
        
        accuracy = (torch.softmax(y_hat,1).argmax(1) == y_truth.long()).float().mean()
        my_accuracy.append(accuracy)
        m_acc = m_acc + accuracy
        
        optimizer.step()
     
      loss_array.append(m_loss / len(my_loss))
      accuracy_array.append(m_acc / len(my_accuracy))
    plt.figure(1)
    plt.subplot(211)
    plt.plot(range(4),accuracy_array)
    plt.xlabel('epoch')
    plt.ylabel('this is accuracy')

    plt.subplot(212)
    plt.plot(range(4),loss_array)
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.show()
    
    final_test_img = testset[172][0].cuda()
    final_test_label = testset[172][1].cuda()
    y_final_img = model(final_test_img.unsqueeze(0))
    print(y_final_img.size(), " this is my size after model")
    

    y_final_img = y_final_img.argmax(dim = 1).squeeze(0).view(512,512)
    y_final_img = y_final_img.cpu()
    y_final_img = y_final_img.data.numpy()
    print(y_final_img.shape, " this is my size")
    plt.imshow(y_final_img)
 
  except:
    __ITB__()
scope()
